{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHcdxYbFTUxtosgRGlGQLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendaverch/brendaverch/blob/main/Redes_Neurais_artificiais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GefGXYhsBcNs"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('credit.pkl', 'rb') as f:\n",
        "  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"
      ],
      "metadata": {
        "id": "3O7k_F4pBs7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_credit = MLPClassifier(max_iter=1500, verbose=False, tol=0.0000100,\n",
        "                                   solver = 'adam', activation = 'relu',\n",
        "                                   hidden_layer_sizes = (50,50))\n",
        "rede_neural_credit.fit(X_credit_treinamento, y_credit_treinamento)\n",
        "#verbose=True mostrar as iterações e os erros\n",
        "#tol= tolerancia do erro\n",
        "#solver é o algoritmo que vai fazer a otimização dos erros. Sgd = stothatic. lbfgs = Newthon. adam(default) = diederik\n",
        "#activation = função de ativação. Identity= degrau. Logistic = sigmoid . Tanh = tangente hiperbolica. Relu(default)  negativo é zerado\n",
        "#hidden_layer_sizes = numero de camadas e neuronios na camada oculta ex: 20,20 20 camadas ocultas com 20 neuronios cada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "hl76d1TjB0Ry",
        "outputId": "edb25335-a0a1-4b05-d3f6-6eddcfa7ff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1500, tol=1e-05)"
            ],
            "text/html": [
              "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1500, tol=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1500, tol=1e-05)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = rede_neural_credit.predict(X_credit_teste)"
      ],
      "metadata": {
        "id": "LErvN4mtCzvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy_score(y_credit_teste, previsoes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NghBitkZHgN_",
        "outputId": "79ebc184-70d6-4a0d-8b74-5508f17c7f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.996"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(rede_neural_credit)\n",
        "cm.fit(X_credit_treinamento, y_credit_treinamento)\n",
        "cm.score(X_credit_teste, y_credit_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "B2ZJTmsjIEHG",
        "outputId": "a99cd5a3-debb-4c1e-fd83-0965b8083ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.996"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_credit_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ole1VVRvIGkA",
        "outputId": "404dffe9-ecae-486f-abf5-3aecab2fe0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       436\n",
            "           1       0.98      0.97      0.98        64\n",
            "\n",
            "    accuracy                           0.99       500\n",
            "   macro avg       0.99      0.98      0.99       500\n",
            "weighted avg       0.99      0.99      0.99       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base Census"
      ],
      "metadata": {
        "id": "MUThJ5yyKHnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('census.pkl', 'rb') as f:\n",
        "  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)"
      ],
      "metadata": {
        "id": "ouoHp6Q1KI8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rede_neural_census = MLPClassifier(verbose=True, max_iter = 1000, tol=0.000010,\n",
        "                                  hidden_layer_sizes = (55,55))\n",
        "rede_neural_census.fit(X_census_treinamento, y_census_treinamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RgY86AUDKK21",
        "outputId": "8b09fd24-ebf3-4985-832e-b70af93c61cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.39653997\n",
            "Iteration 2, loss = 0.32666320\n",
            "Iteration 3, loss = 0.31494619\n",
            "Iteration 4, loss = 0.30841578\n",
            "Iteration 5, loss = 0.30299907\n",
            "Iteration 6, loss = 0.30025791\n",
            "Iteration 7, loss = 0.29665841\n",
            "Iteration 8, loss = 0.29428623\n",
            "Iteration 9, loss = 0.29220840\n",
            "Iteration 10, loss = 0.28951993\n",
            "Iteration 11, loss = 0.28741950\n",
            "Iteration 12, loss = 0.28565649\n",
            "Iteration 13, loss = 0.28362697\n",
            "Iteration 14, loss = 0.28175550\n",
            "Iteration 15, loss = 0.27991667\n",
            "Iteration 16, loss = 0.27815420\n",
            "Iteration 17, loss = 0.27709122\n",
            "Iteration 18, loss = 0.27501066\n",
            "Iteration 19, loss = 0.27331419\n",
            "Iteration 20, loss = 0.27212953\n",
            "Iteration 21, loss = 0.27046244\n",
            "Iteration 22, loss = 0.26925064\n",
            "Iteration 23, loss = 0.26690972\n",
            "Iteration 24, loss = 0.26573624\n",
            "Iteration 25, loss = 0.26418910\n",
            "Iteration 26, loss = 0.26220927\n",
            "Iteration 27, loss = 0.26125412\n",
            "Iteration 28, loss = 0.25938086\n",
            "Iteration 29, loss = 0.25837748\n",
            "Iteration 30, loss = 0.25618071\n",
            "Iteration 31, loss = 0.25461799\n",
            "Iteration 32, loss = 0.25520495\n",
            "Iteration 33, loss = 0.25376204\n",
            "Iteration 34, loss = 0.25223703\n",
            "Iteration 35, loss = 0.25029586\n",
            "Iteration 36, loss = 0.24890608\n",
            "Iteration 37, loss = 0.24757714\n",
            "Iteration 38, loss = 0.24710845\n",
            "Iteration 39, loss = 0.24624921\n",
            "Iteration 40, loss = 0.24526313\n",
            "Iteration 41, loss = 0.24339133\n",
            "Iteration 42, loss = 0.24197117\n",
            "Iteration 43, loss = 0.24120044\n",
            "Iteration 44, loss = 0.23982722\n",
            "Iteration 45, loss = 0.23969742\n",
            "Iteration 46, loss = 0.23798782\n",
            "Iteration 47, loss = 0.23725838\n",
            "Iteration 48, loss = 0.23601369\n",
            "Iteration 49, loss = 0.23525448\n",
            "Iteration 50, loss = 0.23421537\n",
            "Iteration 51, loss = 0.23411575\n",
            "Iteration 52, loss = 0.23283664\n",
            "Iteration 53, loss = 0.23086504\n",
            "Iteration 54, loss = 0.23047800\n",
            "Iteration 55, loss = 0.22979249\n",
            "Iteration 56, loss = 0.22820834\n",
            "Iteration 57, loss = 0.22752034\n",
            "Iteration 58, loss = 0.22721095\n",
            "Iteration 59, loss = 0.22498199\n",
            "Iteration 60, loss = 0.22545739\n",
            "Iteration 61, loss = 0.22406699\n",
            "Iteration 62, loss = 0.22269348\n",
            "Iteration 63, loss = 0.22125171\n",
            "Iteration 64, loss = 0.22074448\n",
            "Iteration 65, loss = 0.22150589\n",
            "Iteration 66, loss = 0.21977617\n",
            "Iteration 67, loss = 0.21872204\n",
            "Iteration 68, loss = 0.21782520\n",
            "Iteration 69, loss = 0.21780999\n",
            "Iteration 70, loss = 0.21677288\n",
            "Iteration 71, loss = 0.21608116\n",
            "Iteration 72, loss = 0.21544883\n",
            "Iteration 73, loss = 0.21441858\n",
            "Iteration 74, loss = 0.21426861\n",
            "Iteration 75, loss = 0.21332293\n",
            "Iteration 76, loss = 0.21153542\n",
            "Iteration 77, loss = 0.21202924\n",
            "Iteration 78, loss = 0.21155878\n",
            "Iteration 79, loss = 0.21066290\n",
            "Iteration 80, loss = 0.21046824\n",
            "Iteration 81, loss = 0.20976067\n",
            "Iteration 82, loss = 0.20899285\n",
            "Iteration 83, loss = 0.20820665\n",
            "Iteration 84, loss = 0.20674637\n",
            "Iteration 85, loss = 0.20727316\n",
            "Iteration 86, loss = 0.20663458\n",
            "Iteration 87, loss = 0.20656706\n",
            "Iteration 88, loss = 0.20605444\n",
            "Iteration 89, loss = 0.20561496\n",
            "Iteration 90, loss = 0.20390330\n",
            "Iteration 91, loss = 0.20407323\n",
            "Iteration 92, loss = 0.20324757\n",
            "Iteration 93, loss = 0.20267494\n",
            "Iteration 94, loss = 0.20153767\n",
            "Iteration 95, loss = 0.20134379\n",
            "Iteration 96, loss = 0.20090320\n",
            "Iteration 97, loss = 0.19987424\n",
            "Iteration 98, loss = 0.20077341\n",
            "Iteration 99, loss = 0.19949914\n",
            "Iteration 100, loss = 0.19948558\n",
            "Iteration 101, loss = 0.20009953\n",
            "Iteration 102, loss = 0.19823036\n",
            "Iteration 103, loss = 0.19835629\n",
            "Iteration 104, loss = 0.19671332\n",
            "Iteration 105, loss = 0.19549851\n",
            "Iteration 106, loss = 0.19513081\n",
            "Iteration 107, loss = 0.19659158\n",
            "Iteration 108, loss = 0.19602375\n",
            "Iteration 109, loss = 0.19345446\n",
            "Iteration 110, loss = 0.19470338\n",
            "Iteration 111, loss = 0.19362171\n",
            "Iteration 112, loss = 0.19288285\n",
            "Iteration 113, loss = 0.19225421\n",
            "Iteration 114, loss = 0.19256576\n",
            "Iteration 115, loss = 0.19134780\n",
            "Iteration 116, loss = 0.19237910\n",
            "Iteration 117, loss = 0.19071710\n",
            "Iteration 118, loss = 0.19119421\n",
            "Iteration 119, loss = 0.19039490\n",
            "Iteration 120, loss = 0.19121676\n",
            "Iteration 121, loss = 0.18939916\n",
            "Iteration 122, loss = 0.18866743\n",
            "Iteration 123, loss = 0.18834666\n",
            "Iteration 124, loss = 0.18832746\n",
            "Iteration 125, loss = 0.18805443\n",
            "Iteration 126, loss = 0.18741943\n",
            "Iteration 127, loss = 0.18704351\n",
            "Iteration 128, loss = 0.18691434\n",
            "Iteration 129, loss = 0.18733573\n",
            "Iteration 130, loss = 0.18644282\n",
            "Iteration 131, loss = 0.18512681\n",
            "Iteration 132, loss = 0.18629429\n",
            "Iteration 133, loss = 0.18450010\n",
            "Iteration 134, loss = 0.18478510\n",
            "Iteration 135, loss = 0.18340659\n",
            "Iteration 136, loss = 0.18283700\n",
            "Iteration 137, loss = 0.18416067\n",
            "Iteration 138, loss = 0.18268801\n",
            "Iteration 139, loss = 0.18355905\n",
            "Iteration 140, loss = 0.18387137\n",
            "Iteration 141, loss = 0.18303290\n",
            "Iteration 142, loss = 0.18232639\n",
            "Iteration 143, loss = 0.18155499\n",
            "Iteration 144, loss = 0.18083354\n",
            "Iteration 145, loss = 0.18071655\n",
            "Iteration 146, loss = 0.18077995\n",
            "Iteration 147, loss = 0.18038260\n",
            "Iteration 148, loss = 0.17959640\n",
            "Iteration 149, loss = 0.17935562\n",
            "Iteration 150, loss = 0.17883947\n",
            "Iteration 151, loss = 0.18020446\n",
            "Iteration 152, loss = 0.17884130\n",
            "Iteration 153, loss = 0.17797432\n",
            "Iteration 154, loss = 0.17661910\n",
            "Iteration 155, loss = 0.17653993\n",
            "Iteration 156, loss = 0.17636788\n",
            "Iteration 157, loss = 0.17794240\n",
            "Iteration 158, loss = 0.17781495\n",
            "Iteration 159, loss = 0.17718586\n",
            "Iteration 160, loss = 0.17736748\n",
            "Iteration 161, loss = 0.17642194\n",
            "Iteration 162, loss = 0.17677819\n",
            "Iteration 163, loss = 0.17764417\n",
            "Iteration 164, loss = 0.17574102\n",
            "Iteration 165, loss = 0.17413801\n",
            "Iteration 166, loss = 0.17469684\n",
            "Iteration 167, loss = 0.17374258\n",
            "Iteration 168, loss = 0.17336288\n",
            "Iteration 169, loss = 0.17511524\n",
            "Iteration 170, loss = 0.17218302\n",
            "Iteration 171, loss = 0.17453168\n",
            "Iteration 172, loss = 0.17284943\n",
            "Iteration 173, loss = 0.17283398\n",
            "Iteration 174, loss = 0.17119167\n",
            "Iteration 175, loss = 0.17089255\n",
            "Iteration 176, loss = 0.17117163\n",
            "Iteration 177, loss = 0.17088007\n",
            "Iteration 178, loss = 0.17169423\n",
            "Iteration 179, loss = 0.17098329\n",
            "Iteration 180, loss = 0.17251208\n",
            "Iteration 181, loss = 0.17082804\n",
            "Iteration 182, loss = 0.17072594\n",
            "Iteration 183, loss = 0.17186712\n",
            "Iteration 184, loss = 0.17036042\n",
            "Iteration 185, loss = 0.16887194\n",
            "Iteration 186, loss = 0.17084603\n",
            "Iteration 187, loss = 0.16894989\n",
            "Iteration 188, loss = 0.16929749\n",
            "Iteration 189, loss = 0.16817053\n",
            "Iteration 190, loss = 0.16719888\n",
            "Iteration 191, loss = 0.16874156\n",
            "Iteration 192, loss = 0.16691802\n",
            "Iteration 193, loss = 0.16659499\n",
            "Iteration 194, loss = 0.16860745\n",
            "Iteration 195, loss = 0.16785021\n",
            "Iteration 196, loss = 0.16690399\n",
            "Iteration 197, loss = 0.16623134\n",
            "Iteration 198, loss = 0.16778219\n",
            "Iteration 199, loss = 0.16546669\n",
            "Iteration 200, loss = 0.16627559\n",
            "Iteration 201, loss = 0.16560732\n",
            "Iteration 202, loss = 0.16555151\n",
            "Iteration 203, loss = 0.16432195\n",
            "Iteration 204, loss = 0.16508805\n",
            "Iteration 205, loss = 0.16474503\n",
            "Iteration 206, loss = 0.16479564\n",
            "Iteration 207, loss = 0.16383127\n",
            "Iteration 208, loss = 0.16481837\n",
            "Iteration 209, loss = 0.16741595\n",
            "Iteration 210, loss = 0.16378214\n",
            "Iteration 211, loss = 0.16311244\n",
            "Iteration 212, loss = 0.16387700\n",
            "Iteration 213, loss = 0.16395485\n",
            "Iteration 214, loss = 0.16271598\n",
            "Iteration 215, loss = 0.16263181\n",
            "Iteration 216, loss = 0.16199554\n",
            "Iteration 217, loss = 0.16141745\n",
            "Iteration 218, loss = 0.16238543\n",
            "Iteration 219, loss = 0.16154565\n",
            "Iteration 220, loss = 0.16102283\n",
            "Iteration 221, loss = 0.16239548\n",
            "Iteration 222, loss = 0.16079768\n",
            "Iteration 223, loss = 0.16079908\n",
            "Iteration 224, loss = 0.16150353\n",
            "Iteration 225, loss = 0.16133483\n",
            "Iteration 226, loss = 0.16088794\n",
            "Iteration 227, loss = 0.16106268\n",
            "Iteration 228, loss = 0.16045937\n",
            "Iteration 229, loss = 0.16093871\n",
            "Iteration 230, loss = 0.16020425\n",
            "Iteration 231, loss = 0.16039134\n",
            "Iteration 232, loss = 0.16245561\n",
            "Iteration 233, loss = 0.15836751\n",
            "Iteration 234, loss = 0.15926271\n",
            "Iteration 235, loss = 0.15912779\n",
            "Iteration 236, loss = 0.15916319\n",
            "Iteration 237, loss = 0.16120104\n",
            "Iteration 238, loss = 0.15938089\n",
            "Iteration 239, loss = 0.15864965\n",
            "Iteration 240, loss = 0.16021342\n",
            "Iteration 241, loss = 0.15821713\n",
            "Iteration 242, loss = 0.15822810\n",
            "Iteration 243, loss = 0.15741324\n",
            "Iteration 244, loss = 0.15671604\n",
            "Iteration 245, loss = 0.15666776\n",
            "Iteration 246, loss = 0.15720985\n",
            "Iteration 247, loss = 0.15728756\n",
            "Iteration 248, loss = 0.15770835\n",
            "Iteration 249, loss = 0.15730703\n",
            "Iteration 250, loss = 0.15540064\n",
            "Iteration 251, loss = 0.15654824\n",
            "Iteration 252, loss = 0.15613963\n",
            "Iteration 253, loss = 0.15569198\n",
            "Iteration 254, loss = 0.15648081\n",
            "Iteration 255, loss = 0.15613416\n",
            "Iteration 256, loss = 0.15451387\n",
            "Iteration 257, loss = 0.15517030\n",
            "Iteration 258, loss = 0.15661354\n",
            "Iteration 259, loss = 0.15447198\n",
            "Iteration 260, loss = 0.15455571\n",
            "Iteration 261, loss = 0.15492910\n",
            "Iteration 262, loss = 0.15472130\n",
            "Iteration 263, loss = 0.15491194\n",
            "Iteration 264, loss = 0.15435024\n",
            "Iteration 265, loss = 0.15443685\n",
            "Iteration 266, loss = 0.15819758\n",
            "Iteration 267, loss = 0.15490843\n",
            "Iteration 268, loss = 0.15349687\n",
            "Iteration 269, loss = 0.15409300\n",
            "Iteration 270, loss = 0.15335797\n",
            "Iteration 271, loss = 0.15249617\n",
            "Iteration 272, loss = 0.15212208\n",
            "Iteration 273, loss = 0.15254500\n",
            "Iteration 274, loss = 0.15090326\n",
            "Iteration 275, loss = 0.15177067\n",
            "Iteration 276, loss = 0.15150784\n",
            "Iteration 277, loss = 0.15215441\n",
            "Iteration 278, loss = 0.15184683\n",
            "Iteration 279, loss = 0.15297378\n",
            "Iteration 280, loss = 0.15358814\n",
            "Iteration 281, loss = 0.15028316\n",
            "Iteration 282, loss = 0.15028710\n",
            "Iteration 283, loss = 0.14986321\n",
            "Iteration 284, loss = 0.15011888\n",
            "Iteration 285, loss = 0.15143507\n",
            "Iteration 286, loss = 0.14963108\n",
            "Iteration 287, loss = 0.15228053\n",
            "Iteration 288, loss = 0.15254839\n",
            "Iteration 289, loss = 0.15032128\n",
            "Iteration 290, loss = 0.15149960\n",
            "Iteration 291, loss = 0.15083439\n",
            "Iteration 292, loss = 0.14913572\n",
            "Iteration 293, loss = 0.14937741\n",
            "Iteration 294, loss = 0.14828675\n",
            "Iteration 295, loss = 0.14858053\n",
            "Iteration 296, loss = 0.14916953\n",
            "Iteration 297, loss = 0.14922909\n",
            "Iteration 298, loss = 0.15203776\n",
            "Iteration 299, loss = 0.14861657\n",
            "Iteration 300, loss = 0.15038933\n",
            "Iteration 301, loss = 0.14856650\n",
            "Iteration 302, loss = 0.14891689\n",
            "Iteration 303, loss = 0.14875246\n",
            "Iteration 304, loss = 0.14770734\n",
            "Iteration 305, loss = 0.14846882\n",
            "Iteration 306, loss = 0.14851465\n",
            "Iteration 307, loss = 0.14871302\n",
            "Iteration 308, loss = 0.14731162\n",
            "Iteration 309, loss = 0.14734682\n",
            "Iteration 310, loss = 0.14636413\n",
            "Iteration 311, loss = 0.14642361\n",
            "Iteration 312, loss = 0.14599576\n",
            "Iteration 313, loss = 0.14700211\n",
            "Iteration 314, loss = 0.14591900\n",
            "Iteration 315, loss = 0.14820208\n",
            "Iteration 316, loss = 0.14773366\n",
            "Iteration 317, loss = 0.14636766\n",
            "Iteration 318, loss = 0.14730341\n",
            "Iteration 319, loss = 0.14488080\n",
            "Iteration 320, loss = 0.14590565\n",
            "Iteration 321, loss = 0.14604119\n",
            "Iteration 322, loss = 0.14590712\n",
            "Iteration 323, loss = 0.14531801\n",
            "Iteration 324, loss = 0.14597972\n",
            "Iteration 325, loss = 0.14638891\n",
            "Iteration 326, loss = 0.14697019\n",
            "Iteration 327, loss = 0.14531394\n",
            "Iteration 328, loss = 0.14445464\n",
            "Iteration 329, loss = 0.14586507\n",
            "Iteration 330, loss = 0.14453990\n",
            "Iteration 331, loss = 0.14587110\n",
            "Iteration 332, loss = 0.14378643\n",
            "Iteration 333, loss = 0.14432013\n",
            "Iteration 334, loss = 0.14332931\n",
            "Iteration 335, loss = 0.14345582\n",
            "Iteration 336, loss = 0.14626771\n",
            "Iteration 337, loss = 0.14334045\n",
            "Iteration 338, loss = 0.14926230\n",
            "Iteration 339, loss = 0.14408774\n",
            "Iteration 340, loss = 0.14448811\n",
            "Iteration 341, loss = 0.14337352\n",
            "Iteration 342, loss = 0.14213478\n",
            "Iteration 343, loss = 0.14383921\n",
            "Iteration 344, loss = 0.14360044\n",
            "Iteration 345, loss = 0.14249464\n",
            "Iteration 346, loss = 0.14221854\n",
            "Iteration 347, loss = 0.14181108\n",
            "Iteration 348, loss = 0.14163006\n",
            "Iteration 349, loss = 0.14071075\n",
            "Iteration 350, loss = 0.14339494\n",
            "Iteration 351, loss = 0.14273876\n",
            "Iteration 352, loss = 0.14191732\n",
            "Iteration 353, loss = 0.14267354\n",
            "Iteration 354, loss = 0.14219393\n",
            "Iteration 355, loss = 0.14272866\n",
            "Iteration 356, loss = 0.14106053\n",
            "Iteration 357, loss = 0.14140650\n",
            "Iteration 358, loss = 0.14215554\n",
            "Iteration 359, loss = 0.14043996\n",
            "Iteration 360, loss = 0.14075053\n",
            "Iteration 361, loss = 0.14112626\n",
            "Iteration 362, loss = 0.14116079\n",
            "Iteration 363, loss = 0.14103575\n",
            "Iteration 364, loss = 0.14041015\n",
            "Iteration 365, loss = 0.14158350\n",
            "Iteration 366, loss = 0.14111119\n",
            "Iteration 367, loss = 0.13998296\n",
            "Iteration 368, loss = 0.13994135\n",
            "Iteration 369, loss = 0.13903636\n",
            "Iteration 370, loss = 0.14006017\n",
            "Iteration 371, loss = 0.13984571\n",
            "Iteration 372, loss = 0.14071381\n",
            "Iteration 373, loss = 0.14256264\n",
            "Iteration 374, loss = 0.13838699\n",
            "Iteration 375, loss = 0.14005473\n",
            "Iteration 376, loss = 0.14024859\n",
            "Iteration 377, loss = 0.14037397\n",
            "Iteration 378, loss = 0.14065053\n",
            "Iteration 379, loss = 0.14080342\n",
            "Iteration 380, loss = 0.13983471\n",
            "Iteration 381, loss = 0.13871715\n",
            "Iteration 382, loss = 0.13800070\n",
            "Iteration 383, loss = 0.13812918\n",
            "Iteration 384, loss = 0.13814143\n",
            "Iteration 385, loss = 0.13920555\n",
            "Iteration 386, loss = 0.13882397\n",
            "Iteration 387, loss = 0.13875496\n",
            "Iteration 388, loss = 0.13813137\n",
            "Iteration 389, loss = 0.13870284\n",
            "Iteration 390, loss = 0.13782652\n",
            "Iteration 391, loss = 0.13838883\n",
            "Iteration 392, loss = 0.13775267\n",
            "Iteration 393, loss = 0.13712243\n",
            "Iteration 394, loss = 0.13607405\n",
            "Iteration 395, loss = 0.13823317\n",
            "Iteration 396, loss = 0.13654585\n",
            "Iteration 397, loss = 0.13791646\n",
            "Iteration 398, loss = 0.13920440\n",
            "Iteration 399, loss = 0.13775537\n",
            "Iteration 400, loss = 0.13685372\n",
            "Iteration 401, loss = 0.13765610\n",
            "Iteration 402, loss = 0.13779139\n",
            "Iteration 403, loss = 0.13610669\n",
            "Iteration 404, loss = 0.13713357\n",
            "Iteration 405, loss = 0.13677017\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(55, 55), max_iter=1000, tol=1e-05,\n",
              "              verbose=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes = rede_neural_census.predict(X_census_teste)\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIeIkU71KS-C",
        "outputId": "98eebc6f-6f1b-4ee2-86e5-d9c55c1d2bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
              "      dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy_score(y_census_teste, previsoes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86Ukfz88KVou",
        "outputId": "e1b8de97-cff2-47d8-8862-6604a516ff4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8114636642784033"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(rede_neural_census)\n",
        "cm.fit(X_census_treinamento, y_census_treinamento)\n",
        "cm.score(X_census_teste, y_census_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "FziuZMTHKWUc",
        "outputId": "be5fcc75-36a4-481c-a4bf-4120e150f3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8114636642784033"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_census_teste, previsoes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nndzouJzKYwo",
        "outputId": "3c7032c6-38f5-4f90-f7e5-139a2bec1f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.88      0.88      3693\n",
            "        >50K       0.62      0.60      0.61      1192\n",
            "\n",
            "    accuracy                           0.81      4885\n",
            "   macro avg       0.74      0.74      0.74      4885\n",
            "weighted avg       0.81      0.81      0.81      4885\n",
            "\n"
          ]
        }
      ]
    }
  ]
}